{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Oral_Detect_my_ResNet",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leekate/2020-ctrc-OralCancer-Classification-project/blob/master/Oral_Detect_my_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaG0rSYYS4Fv",
        "outputId": "ebb04d27-2ce5-4f4c-df7f-d0980f974259"
      },
      "source": [
        "!pip uninstall keras\n",
        "!pip install Keras==2.2.4\n",
        "\n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.13.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjZvpxdttb44",
        "outputId": "bd358591-93bc-4ca3-8166-b9c6ba24a7c3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs41ZPr1TMQX"
      },
      "source": [
        "## 원본 데이터 파일 갯수 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDhNXLavtNVu",
        "outputId": "95afc8c8-351d-4591-d1fa-6315922bd864"
      },
      "source": [
        "import os\n",
        "\n",
        "ori_length1= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/Original/train/1.Cancer\"\n",
        "ori_length2= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/Original/validation/1.Cancer\"\n",
        "ori_plus1= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/Original/test/1.Cancer\"\n",
        "\n",
        "ori_file_list1 = os.listdir(ori_length1)\n",
        "ori_file_list2 = os.listdir(ori_length2)\n",
        "ori_plus_list1 = os.listdir(ori_plus1)\n",
        "\n",
        "print(\"cancer\")\n",
        "print(len(ori_file_list1))\n",
        "print(len(ori_file_list2))\n",
        "print(len(ori_plus_list1))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cancer\n",
            "124\n",
            "143\n",
            "143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn4xCaEUtNV7",
        "outputId": "2dfc801c-82bb-4498-f1ff-7b05956247eb"
      },
      "source": [
        "ori_length3= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/Original/train/2.Precancer\"\n",
        "ori_length4= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/Original/validation/2.Precancer\"\n",
        "ori_plus2= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/Original/test/2.Precancer\"\n",
        "\n",
        "ori_file_list3 = os.listdir(ori_length3)\n",
        "ori_file_list4 = os.listdir(ori_length4)\n",
        "ori_plus_list2 = os.listdir(ori_plus2)\n",
        "\n",
        "print(\"precancer\")\n",
        "print(len(ori_file_list3))\n",
        "print(len(ori_file_list4))\n",
        "print(len(ori_plus_list2))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precancer\n",
            "46\n",
            "52\n",
            "52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DPAzN7ttNV9",
        "outputId": "eee6445d-e05e-4547-955e-d6b942bff02f"
      },
      "source": [
        "ori_length5 = \"/content/drive/Shareddrives/CTRC-OralDetect-Project/Original/train/3.Inflammatory\"\n",
        "ori_length6 = \"/content/drive/Shareddrives/CTRC-OralDetect-Project/Original/validation/3.Inflammatory\"\n",
        "ori_plus3= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/Original/test/3.Inflammatory\"\n",
        "\n",
        "ori_file_list5 = os.listdir(ori_length5)\n",
        "ori_file_list6 = os.listdir(ori_length6)\n",
        "ori_plus_list3 = os.listdir(ori_plus3)\n",
        "\n",
        "print(\"extra\")\n",
        "print(len(ori_file_list5))\n",
        "print(len(ori_file_list6))\n",
        "print(len(ori_plus_list3))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "extra\n",
            "79\n",
            "93\n",
            "93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsu6PdcStNV_",
        "outputId": "640a1c59-fdb9-4d93-a9b8-2a6b32ad4587"
      },
      "source": [
        "ori_length7 = \"/content/drive/Shareddrives/CTRC-OralDetect-Project/Original/train/4.Normal\"\n",
        "ori_length8 = \"/content/drive/Shareddrives/CTRC-OralDetect-Project/Original/validation/4.Normal\"\n",
        "ori_plus4= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/Original/test/4.Normal\"\n",
        "\n",
        "ori_file_list7 = os.listdir(ori_length7)\n",
        "ori_file_list8 = os.listdir(ori_length8)\n",
        "ori_plus_list4 = os.listdir(ori_plus4)\n",
        "\n",
        "print(\"normal\")\n",
        "print(len(ori_file_list7))\n",
        "print(len(ori_file_list8))\n",
        "print(len(ori_plus_list4))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "normal\n",
            "455\n",
            "341\n",
            "341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "CnWuxkL3tNWA",
        "outputId": "a0eafc55-1ace-4053-8b6a-a62a034a9bfd"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#df = df_maker(3,4,0)  # 3X3 데이터 프레임 생성 0으로 채움\n",
        "col = [\"Train image\",\"Validation Image\",\"Test Image\",\"Total Image\"]\n",
        "ind = [\"Cancer\",\"Precancer\",\"Extra\",\"Normal\",\"TOTAL\"]\n",
        "#df.columns = col  # 컬럼 col 리스트로 덮어씌움\n",
        "#df.index = ind    # 인덱스 ind 리스트로 덮어씌움\n",
        "\n",
        "\n",
        "con = [\n",
        "       [len(ori_file_list1),len(ori_file_list2),len(ori_plus_list1),len(ori_plus_list1)+len(ori_file_list1)+len(ori_file_list2)], \n",
        "\n",
        "       [len(ori_file_list3),len(ori_file_list4),len(ori_plus_list2),len(ori_plus_list2)+len(ori_file_list3)+len(ori_file_list4)],\n",
        "\n",
        "       [len(ori_file_list5),len(ori_file_list6),len(ori_plus_list3),len(ori_plus_list3)+len(ori_file_list5)+len(ori_file_list6)],\n",
        "\n",
        "       [len(ori_file_list7),len(ori_file_list8),len(ori_plus_list4),len(ori_plus_list4)+len(ori_file_list7)+len(ori_file_list8)],\n",
        "\n",
        "        [len(ori_file_list1)+len(ori_file_list3)+len(ori_file_list5)+len(ori_file_list7),\n",
        "         len(ori_file_list2)+len(ori_file_list4)+len(ori_file_list6)+len(ori_file_list8),\n",
        "         len(ori_plus_list1)+len(ori_plus_list2)+len(ori_plus_list3)+len(ori_plus_list4),\n",
        "        len(ori_file_list1)+len(ori_file_list3)+len(ori_file_list5)+len(ori_file_list7)+len(ori_file_list2)+len(ori_file_list4)+len(ori_file_list6)+len(ori_file_list8)+len(ori_plus_list1)+len(ori_plus_list2)+len(ori_plus_list3)+len(ori_plus_list4)]\n",
        "       ]\n",
        "\n",
        "pd.DataFrame(con,columns=col, index=ind)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train image</th>\n",
              "      <th>Validation Image</th>\n",
              "      <th>Test Image</th>\n",
              "      <th>Total Image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cancer</th>\n",
              "      <td>124</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precancer</th>\n",
              "      <td>46</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Extra</th>\n",
              "      <td>79</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Normal</th>\n",
              "      <td>455</td>\n",
              "      <td>341</td>\n",
              "      <td>341</td>\n",
              "      <td>1137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOTAL</th>\n",
              "      <td>704</td>\n",
              "      <td>629</td>\n",
              "      <td>629</td>\n",
              "      <td>1962</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Train image  Validation Image  Test Image  Total Image\n",
              "Cancer             124               143         143          410\n",
              "Precancer           46                52          52          150\n",
              "Extra               79                93          93          265\n",
              "Normal             455               341         341         1137\n",
              "TOTAL              704               629         629         1962"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iey8Fnt912HF"
      },
      "source": [
        "# 단순 증량 후 최종 파일 갯수 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCzsyyBF5qxD",
        "outputId": "5ff983ff-753a-40a3-d448-869258e286d6"
      },
      "source": [
        "length1= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/OriginDataGenerate/train/1.Cancer\"\n",
        "length2= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/OriginDataGenerate/validation/1.Cancer\"\n",
        "plus1= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/OriginDataGenerate/test/1.Cancer\"\n",
        "\n",
        "file_list1 = os.listdir(length1)\n",
        "file_list2 = os.listdir(length2)\n",
        "plus_list1 = os.listdir(plus1)\n",
        "\n",
        "print(\"cancer\")\n",
        "print(len(file_list1))\n",
        "print(len(file_list2))\n",
        "print(len(plus_list1))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cancer\n",
            "496\n",
            "143\n",
            "143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP9b29_351jm",
        "outputId": "220a3a0e-55aa-4c9d-a2e2-1fae43508778"
      },
      "source": [
        "length3= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/OriginDataGenerate/train/2.Precancer\"\n",
        "length4= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/OriginDataGenerate/validation/2.Precancer\"\n",
        "plus2= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/OriginDataGenerate/test/2.Precancer\"\n",
        "\n",
        "file_list3 = os.listdir(length3)\n",
        "file_list4 = os.listdir(length4)\n",
        "plus_list2 = os.listdir(plus2)\n",
        "\n",
        "print(\"precancer\")\n",
        "print(len(file_list3))\n",
        "print(len(file_list4))\n",
        "print(len(plus_list2))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precancer\n",
            "184\n",
            "52\n",
            "52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f319fQE5_rT",
        "outputId": "b46cfa83-4247-41e2-f23f-2cf6e0fc2e79"
      },
      "source": [
        "length5 = \"/content/drive/Shareddrives/CTRC-OralDetect-Project/OriginDataGenerate/train/3.Inflammatory\"\n",
        "length6 = \"/content/drive/Shareddrives/CTRC-OralDetect-Project/OriginDataGenerate/validation/3.Inflammatory\"\n",
        "plus3= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/OriginDataGenerate/test/3.Inflammatory\"\n",
        "\n",
        "file_list5 = os.listdir(length5)\n",
        "file_list6 = os.listdir(length6)\n",
        "plus_list3 = os.listdir(plus3)\n",
        "\n",
        "print(\"extra\")\n",
        "print(len(file_list5))\n",
        "print(len(file_list6))\n",
        "print(len(plus_list3))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "extra\n",
            "316\n",
            "93\n",
            "93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7_lH9tm6HUw",
        "outputId": "fb09b8b3-04cb-4dea-e431-c6db4381d5eb"
      },
      "source": [
        "length7 = \"/content/drive/Shareddrives/CTRC-OralDetect-Project/OriginDataGenerate/train/4.Normal\"\n",
        "length8 = \"/content/drive/Shareddrives/CTRC-OralDetect-Project/OriginDataGenerate/validation/4.Normal\"\n",
        "plus4= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/OriginDataGenerate/test/4.Normal\"\n",
        "\n",
        "file_list7 = os.listdir(length7)\n",
        "file_list8 = os.listdir(length8)\n",
        "plus_list4 = os.listdir(plus4)\n",
        "\n",
        "print(\"normal\")\n",
        "print(len(file_list7))\n",
        "print(len(file_list8))\n",
        "print(len(plus_list4))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "normal\n",
            "1365\n",
            "341\n",
            "341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFbhCcJZqyYF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "93e78b3d-b66b-4c5c-809b-19ddaee5cf04"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#df = df_maker(3,4,0)  # 3X3 데이터 프레임 생성 0으로 채움\n",
        "col = [\"Train image\",\"Validation Image\",\"Test Image\",\"Total Image\"]\n",
        "ind = [\"Cancer\",\"Precancer\",\"Extra\",\"Normal\",\"TOTAL\"]\n",
        "#df.columns = col  # 컬럼 col 리스트로 덮어씌움\n",
        "#df.index = ind    # 인덱스 ind 리스트로 덮어씌움\n",
        "\n",
        "\n",
        "con = [\n",
        "       [len(file_list1),len(file_list2),len(plus_list1),len(plus_list1)+len(file_list1)+len(file_list2)], \n",
        "       [len(file_list3),len(file_list4),len(plus_list2),len(plus_list2)+len(file_list3)+len(file_list4)],\n",
        "       [len(file_list5),len(file_list6),len(plus_list3),len(plus_list3)+len(file_list5)+len(file_list6)],\n",
        "       [len(file_list7),len(file_list8),len(plus_list4),len(plus_list4)+len(file_list7)+len(file_list8)],\n",
        "\n",
        "        [len(file_list1)+len(file_list3)+len(file_list5)+len(file_list7),\n",
        "         len(file_list2)+len(file_list4)+len(file_list6)+len(file_list8),\n",
        "         len(plus_list1)+len(plus_list2)+len(plus_list3)+len(plus_list4),\n",
        "        len(file_list1)+len(file_list3)+len(file_list5)+len(file_list7)+len(file_list2)+len(file_list4)+len(file_list6)+len(file_list8)+len(plus_list1)+len(plus_list2)+len(plus_list3)+len(plus_list4)]\n",
        "       ]\n",
        "\n",
        "pd.DataFrame(con,columns=col, index=ind)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train image</th>\n",
              "      <th>Validation Image</th>\n",
              "      <th>Test Image</th>\n",
              "      <th>Total Image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cancer</th>\n",
              "      <td>496</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precancer</th>\n",
              "      <td>184</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Extra</th>\n",
              "      <td>316</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Normal</th>\n",
              "      <td>1365</td>\n",
              "      <td>341</td>\n",
              "      <td>341</td>\n",
              "      <td>2047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOTAL</th>\n",
              "      <td>2361</td>\n",
              "      <td>629</td>\n",
              "      <td>629</td>\n",
              "      <td>3619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Train image  Validation Image  Test Image  Total Image\n",
              "Cancer             496               143         143          782\n",
              "Precancer          184                52          52          288\n",
              "Extra              316                93          93          502\n",
              "Normal            1365               341         341         2047\n",
              "TOTAL             2361               629         629         3619"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh0lSpy8aBIa"
      },
      "source": [
        "# Histogram Equalization 한 데이터 양"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx-mrq0SaEzu",
        "outputId": "e2c9bf61-ef67-4bd7-bf15-b786cb71277d"
      },
      "source": [
        "length1= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/train/1.Cancer\"\n",
        "length2= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/validation/1.Cancer\"\n",
        "plus1= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/test/1.Cancer\"\n",
        "\n",
        "file_list1 = os.listdir(length1)\n",
        "file_list2 = os.listdir(length2)\n",
        "plus_list1 = os.listdir(plus1)\n",
        "\n",
        "print(\"cancer\")\n",
        "print(len(file_list1))\n",
        "print(len(file_list2))\n",
        "print(len(plus_list1))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cancer\n",
            "496\n",
            "143\n",
            "143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MafpLePEaEzv",
        "outputId": "0651c752-a175-418c-ccae-0af4e42fd17e"
      },
      "source": [
        "length3= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/train/2.Precancer\"\n",
        "length4= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/validation/2.Precancer\"\n",
        "plus2= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/test/2.Precancer\"\n",
        "\n",
        "file_list3 = os.listdir(length3)\n",
        "file_list4 = os.listdir(length4)\n",
        "plus_list2 = os.listdir(plus2)\n",
        "\n",
        "print(\"precancer\")\n",
        "print(len(file_list3))\n",
        "print(len(file_list4))\n",
        "print(len(plus_list2))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precancer\n",
            "184\n",
            "52\n",
            "52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1uZKM8laEzv",
        "outputId": "c3480883-35fb-4275-b6ac-d3ac17f50838"
      },
      "source": [
        "length5 = \"/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/train/3.Inflammatory\"\n",
        "length6 = \"/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/validation/3.Inflammatory\"\n",
        "plus3= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/test/3.Inflammatory\"\n",
        "\n",
        "file_list5 = os.listdir(length5)\n",
        "file_list6 = os.listdir(length6)\n",
        "plus_list3 = os.listdir(plus3)\n",
        "\n",
        "print(\"extra\")\n",
        "print(len(file_list5))\n",
        "print(len(file_list6))\n",
        "print(len(plus_list3))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "extra\n",
            "316\n",
            "93\n",
            "93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3f_Jsu3aEzv",
        "outputId": "018fa6fa-80da-472a-da4e-cdba05f0f551"
      },
      "source": [
        "length7 = \"/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/train/4.Normal\"\n",
        "length8 = \"/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/validation/4.Normal\"\n",
        "plus4= \"/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/test/4.Normal\"\n",
        "\n",
        "file_list7 = os.listdir(length7)\n",
        "file_list8 = os.listdir(length8)\n",
        "plus_list4 = os.listdir(plus4)\n",
        "\n",
        "print(\"normal\")\n",
        "print(len(file_list7))\n",
        "print(len(file_list8))\n",
        "print(len(plus_list4))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "normal\n",
            "1365\n",
            "341\n",
            "341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nxuojL9faEzv",
        "outputId": "6f559637-7807-46ab-8698-5abf9090f1cb"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#df = df_maker(3,4,0)  # 3X3 데이터 프레임 생성 0으로 채움\n",
        "col = [\"Train image\",\"Validation Image\",\"Test Image\",\"Total Image\"]\n",
        "ind = [\"Cancer\",\"Precancer\",\"Extra\",\"Normal\",\"TOTAL\"]\n",
        "#df.columns = col  # 컬럼 col 리스트로 덮어씌움\n",
        "#df.index = ind    # 인덱스 ind 리스트로 덮어씌움\n",
        "\n",
        "\n",
        "con = [\n",
        "       [len(file_list1),len(file_list2),len(plus_list1),len(plus_list1)+len(file_list1)+len(file_list2)], \n",
        "       [len(file_list3),len(file_list4),len(plus_list2),len(plus_list2)+len(file_list3)+len(file_list4)],\n",
        "       [len(file_list5),len(file_list6),len(plus_list3),len(plus_list3)+len(file_list5)+len(file_list6)],\n",
        "       [len(file_list7),len(file_list8),len(plus_list4),len(plus_list4)+len(file_list7)+len(file_list8)],\n",
        "\n",
        "        [len(file_list1)+len(file_list3)+len(file_list5)+len(file_list7),\n",
        "         len(file_list2)+len(file_list4)+len(file_list6)+len(file_list8),\n",
        "         len(plus_list1)+len(plus_list2)+len(plus_list3)+len(plus_list4),\n",
        "        len(file_list1)+len(file_list3)+len(file_list5)+len(file_list7)+len(file_list2)+len(file_list4)+len(file_list6)+len(file_list8)+len(plus_list1)+len(plus_list2)+len(plus_list3)+len(plus_list4)]\n",
        "       ]\n",
        "\n",
        "pd.DataFrame(con,columns=col, index=ind)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train image</th>\n",
              "      <th>Validation Image</th>\n",
              "      <th>Test Image</th>\n",
              "      <th>Total Image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cancer</th>\n",
              "      <td>496</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precancer</th>\n",
              "      <td>184</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Extra</th>\n",
              "      <td>316</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Normal</th>\n",
              "      <td>1365</td>\n",
              "      <td>341</td>\n",
              "      <td>341</td>\n",
              "      <td>2047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOTAL</th>\n",
              "      <td>2361</td>\n",
              "      <td>629</td>\n",
              "      <td>629</td>\n",
              "      <td>3619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Train image  Validation Image  Test Image  Total Image\n",
              "Cancer             496               143         143          782\n",
              "Precancer          184                52          52          288\n",
              "Extra              316                93          93          502\n",
              "Normal            1365               341         341         2047\n",
              "TOTAL             2361               629         629         3619"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyA2NmdWUiNS"
      },
      "source": [
        "# 본격적인 설계 시작\r\n",
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxP_mlUlUypu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2804a4e-1524-47b0-d0a4-c2b3aa89bc1a"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "conv_base=ResNet50(weights='imagenet',\n",
        "                include_top=False,\n",
        "                input_shape=(150,150,3))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUIYq1z97J1x"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
        "\n",
        "\n",
        "\n",
        "model=models.Sequential()\n",
        "model.add(conv_base)\n",
        "\n",
        "\n",
        "\n",
        "model.add(layers.Dense(2048, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(2048, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add( MaxPooling2D((2,2), padding='same'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.add(layers.Dense(1024, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(1024, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(1024, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(1024, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(1024, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(1024, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(1024, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.add(layers.Dense(512, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(512, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(512, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(512, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(512, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(512, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(512, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(512, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(512, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(512, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(512, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(512, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(256, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.add(layers.Dense(128, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(128, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(128, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(128, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(128, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(128, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "model.add(layers.Dense(128, kernel_regularizer = regularizers.l2\n",
        "                                  (0.001),activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten()) \n",
        "model.add(layers.Dense(64,activation='relu'))\n",
        "model.add(layers.Dense(4,activation='relu'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUoJFTRXVwKq"
      },
      "source": [
        "conv_base.trainable=False\n",
        "#weight가 업데이트되지 않도록"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBHDJIbPVzgX",
        "outputId": "f0fa9fd4-4133-4058-b489-d13d3b42153a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 5, 5, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5, 5, 2048)        4196352   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5, 5, 2048)        4196352   \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 3, 3, 2048)        0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3, 3, 1024)        2098176   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3, 3, 1024)        1049600   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3, 3, 1024)        1049600   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3, 3, 1024)        1049600   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3, 3, 1024)        1049600   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3, 3, 1024)        1049600   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3, 3, 1024)        1049600   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3, 3, 512)         524800    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3, 3, 512)         262656    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3, 3, 512)         262656    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 3, 3, 512)         262656    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3, 3, 512)         262656    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3, 3, 512)         262656    \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 3, 3, 512)         262656    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 3, 3, 512)         262656    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 3, 3, 512)         262656    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 3, 3, 512)         262656    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 3, 3, 512)         262656    \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 3, 3, 512)         262656    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 3, 3, 256)         131328    \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 3, 3, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 3, 3, 128)         32896     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 3, 3, 128)         16512     \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 3, 3, 128)         16512     \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 3, 3, 128)         16512     \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 3, 3, 128)         16512     \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 3, 3, 128)         16512     \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 3, 3, 128)         16512     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 64)                73792     \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 45,246,020\n",
            "Trainable params: 21,658,308\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPdOP7Jgb_L9"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAl8-NfMqyYa"
      },
      "source": [
        "from keras.models import load_model\n",
        "import os\n",
        "# model checkpoint\n",
        "model_sav_path = '/content/drive/Shareddrives/CTRC-OralDetect-Project/jiwoo_model/ResNet50'\n",
        "\n",
        "if not os.path.isdir(model_sav_path):\n",
        "    os.mkdir(model_sav_path)\n",
        "    \n",
        "model_path = model_sav_path + 'my_Resnet_model.h5'\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PwK5pLAqyYb"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow.keras\n",
        "early_stopping = EarlyStopping()\n",
        "\n",
        "callbacks=[tensorflow.keras.callbacks.TensorBoard(\n",
        "    log_dir='my_log_dir',\n",
        "    histogram_freq=1,\n",
        "    embeddings_freq=1,),\n",
        "    early_stopping]\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZijRt-PLQRLY"
      },
      "source": [
        "train_dir='/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/train'\r\n",
        "validation_dir='/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/validation'\r\n",
        "test_dir='/content/drive/Shareddrives/CTRC-OralDetect-Project/NewDataGenerate-HM/test'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPrY3GdxYo9J",
        "outputId": "b059c65e-352a-4c29-9bdc-d6edca5a486a"
      },
      "source": [
        "import os\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array, load_img\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "np.random.seed(3)\r\n",
        "\r\n",
        "imageGenerator = ImageDataGenerator(rescale=1./255)\r\n",
        "trainGen = imageGenerator.flow_from_directory(train_dir,\r\n",
        "                                              target_size=(150,150))\r\n",
        "                                            \r\n",
        "\r\n",
        "validationGen = imageGenerator.flow_from_directory(validation_dir,\r\n",
        "                                              target_size=(150,150))\r\n",
        "                                              \r\n",
        "testGen = imageGenerator.flow_from_directory(test_dir,\r\n",
        "                                              target_size=(150,150))\r\n",
        "                                            \r\n",
        "                                    "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2361 images belonging to 4 classes.\n",
            "Found 629 images belonging to 4 classes.\n",
            "Found 629 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YIPH8lv4wpj"
      },
      "source": [
        "* steps_per_epoch : 한 epoch에 사용한 스텝 수를 지정합니다. 총 2361개의 훈련 샘플이 있고 배치사이즈가 32이므로 73 스텝으로 지정합니다.\n",
        "* validation_data : 검증데이터셋을 제공할 제네레이터를 지정합니다. 여기서는 앞서 생성한 validation_generator으로 지정합니다.\n",
        "* validation_steps : 한 epoch 종료 시 마다 검증할 때 사용되는 검증 스텝 수를 지정합니다. 총 629개의 검증 샘플이 있고 배치사이즈가 32이므로 19 스텝으로 지정합니다.\n",
        "* epochs : 전체 훈련 데이터셋에 대해 학습 반복 횟수를 지정합니다. 50번을 반복적으로 학습시켜 보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCWTsh08qyYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a5027c-d3e3-40a8-c060-15116fe06ee3"
      },
      "source": [
        "history=model.fit_generator(trainGen,steps_per_epoch=73, epochs=50,\n",
        "                  validation_data=validationGen,validation_steps=19,\n",
        "                           callbacks=callbacks)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "73/73 [==============================] - 769s 11s/step - loss: 15.6179 - accuracy: 0.5766 - val_loss: 12.0684 - val_accuracy: 0.5477\n",
            "Epoch 2/50\n",
            "73/73 [==============================] - 32s 436ms/step - loss: 10.3771 - accuracy: 0.6376 - val_loss: 9.1785 - val_accuracy: 0.5395\n",
            "Epoch 3/50\n",
            "73/73 [==============================] - 32s 439ms/step - loss: 8.0698 - accuracy: 0.6505 - val_loss: 7.4602 - val_accuracy: 0.5378\n",
            "Epoch 4/50\n",
            "73/73 [==============================] - 32s 432ms/step - loss: 6.4683 - accuracy: 0.6861 - val_loss: 6.4322 - val_accuracy: 0.5395\n",
            "Epoch 5/50\n",
            "73/73 [==============================] - 32s 434ms/step - loss: 5.4929 - accuracy: 0.6690 - val_loss: 5.2678 - val_accuracy: 0.5395\n",
            "Epoch 6/50\n",
            "73/73 [==============================] - 32s 434ms/step - loss: 4.8358 - accuracy: 0.5771 - val_loss: 4.5286 - val_accuracy: 0.5378\n",
            "Epoch 7/50\n",
            "73/73 [==============================] - 32s 429ms/step - loss: 4.1945 - accuracy: 0.5801 - val_loss: 3.9762 - val_accuracy: 0.5395\n",
            "Epoch 8/50\n",
            "73/73 [==============================] - 32s 430ms/step - loss: 3.7036 - accuracy: 0.5749 - val_loss: 3.5398 - val_accuracy: 0.5378\n",
            "Epoch 9/50\n",
            "73/73 [==============================] - 31s 426ms/step - loss: 3.3066 - accuracy: 0.5784 - val_loss: 3.1764 - val_accuracy: 0.5461\n",
            "Epoch 10/50\n",
            "73/73 [==============================] - 31s 427ms/step - loss: 2.9873 - accuracy: 0.5784 - val_loss: 2.8948 - val_accuracy: 0.5411\n",
            "Epoch 11/50\n",
            "73/73 [==============================] - 31s 428ms/step - loss: 2.7297 - accuracy: 0.5771 - val_loss: 2.6512 - val_accuracy: 0.5444\n",
            "Epoch 12/50\n",
            "73/73 [==============================] - 31s 429ms/step - loss: 2.5165 - accuracy: 0.5771 - val_loss: 2.4692 - val_accuracy: 0.5428\n",
            "Epoch 13/50\n",
            "73/73 [==============================] - 31s 424ms/step - loss: 2.3343 - accuracy: 0.5779 - val_loss: 2.2939 - val_accuracy: 0.5444\n",
            "Epoch 14/50\n",
            "73/73 [==============================] - 31s 424ms/step - loss: 2.1817 - accuracy: 0.5779 - val_loss: 2.1591 - val_accuracy: 0.5411\n",
            "Epoch 15/50\n",
            "73/73 [==============================] - 31s 425ms/step - loss: 2.0541 - accuracy: 0.5792 - val_loss: 2.0377 - val_accuracy: 0.5411\n",
            "Epoch 16/50\n",
            "73/73 [==============================] - 31s 427ms/step - loss: 1.9438 - accuracy: 0.5792 - val_loss: 1.9387 - val_accuracy: 0.5461\n",
            "Epoch 17/50\n",
            "73/73 [==============================] - 31s 427ms/step - loss: 1.8546 - accuracy: 0.5788 - val_loss: 1.8521 - val_accuracy: 0.5477\n",
            "Epoch 18/50\n",
            "73/73 [==============================] - 31s 425ms/step - loss: 1.7702 - accuracy: 0.5805 - val_loss: 1.7820 - val_accuracy: 0.5428\n",
            "Epoch 19/50\n",
            "73/73 [==============================] - 31s 424ms/step - loss: 1.7037 - accuracy: 0.5796 - val_loss: 1.7236 - val_accuracy: 0.5395\n",
            "Epoch 20/50\n",
            "73/73 [==============================] - 31s 427ms/step - loss: 1.6454 - accuracy: 0.5796 - val_loss: 1.6651 - val_accuracy: 0.5428\n",
            "Epoch 21/50\n",
            "73/73 [==============================] - 32s 433ms/step - loss: 1.5942 - accuracy: 0.5784 - val_loss: 1.6232 - val_accuracy: 0.5411\n",
            "Epoch 22/50\n",
            "73/73 [==============================] - 32s 431ms/step - loss: 1.5468 - accuracy: 0.5801 - val_loss: 1.5754 - val_accuracy: 0.5428\n",
            "Epoch 23/50\n",
            "73/73 [==============================] - 32s 436ms/step - loss: 1.5077 - accuracy: 0.5784 - val_loss: 1.5366 - val_accuracy: 0.5411\n",
            "Epoch 24/50\n",
            "73/73 [==============================] - 31s 427ms/step - loss: 1.4759 - accuracy: 0.5762 - val_loss: 1.5170 - val_accuracy: 0.5378\n",
            "Epoch 25/50\n",
            "73/73 [==============================] - 32s 432ms/step - loss: 1.4462 - accuracy: 0.5775 - val_loss: 1.4756 - val_accuracy: 0.5428\n",
            "Epoch 26/50\n",
            "73/73 [==============================] - 31s 424ms/step - loss: 1.4138 - accuracy: 0.5805 - val_loss: 1.4452 - val_accuracy: 0.5461\n",
            "Epoch 27/50\n",
            "73/73 [==============================] - 31s 426ms/step - loss: 1.3950 - accuracy: 0.5771 - val_loss: 1.4326 - val_accuracy: 0.5395\n",
            "Epoch 28/50\n",
            "73/73 [==============================] - 31s 425ms/step - loss: 1.3677 - accuracy: 0.5805 - val_loss: 1.4088 - val_accuracy: 0.5395\n",
            "Epoch 29/50\n",
            "73/73 [==============================] - 31s 422ms/step - loss: 1.3533 - accuracy: 0.5775 - val_loss: 1.3960 - val_accuracy: 0.5378\n",
            "Epoch 30/50\n",
            "73/73 [==============================] - 31s 422ms/step - loss: 1.3338 - accuracy: 0.5788 - val_loss: 1.3830 - val_accuracy: 0.5411\n",
            "Epoch 31/50\n",
            "73/73 [==============================] - 31s 424ms/step - loss: 1.3203 - accuracy: 0.5779 - val_loss: 1.3657 - val_accuracy: 0.5395\n",
            "Epoch 32/50\n",
            "73/73 [==============================] - 31s 422ms/step - loss: 1.3082 - accuracy: 0.5771 - val_loss: 1.3470 - val_accuracy: 0.5428\n",
            "Epoch 33/50\n",
            "73/73 [==============================] - 31s 420ms/step - loss: 1.2937 - accuracy: 0.5784 - val_loss: 1.3290 - val_accuracy: 0.5428\n",
            "Epoch 34/50\n",
            "73/73 [==============================] - 31s 422ms/step - loss: 1.2819 - accuracy: 0.5788 - val_loss: 1.3168 - val_accuracy: 0.5461\n",
            "Epoch 35/50\n",
            "73/73 [==============================] - 31s 422ms/step - loss: 1.2698 - accuracy: 0.5805 - val_loss: 1.3113 - val_accuracy: 0.5444\n",
            "Epoch 36/50\n",
            "73/73 [==============================] - 31s 422ms/step - loss: 1.2605 - accuracy: 0.5801 - val_loss: 1.2999 - val_accuracy: 0.5444\n",
            "Epoch 37/50\n",
            "73/73 [==============================] - 31s 417ms/step - loss: 1.2536 - accuracy: 0.5788 - val_loss: 1.2939 - val_accuracy: 0.5444\n",
            "Epoch 38/50\n",
            "73/73 [==============================] - 31s 422ms/step - loss: 1.2439 - accuracy: 0.5796 - val_loss: 1.2933 - val_accuracy: 0.5378\n",
            "Epoch 39/50\n",
            "73/73 [==============================] - 31s 419ms/step - loss: 1.2365 - accuracy: 0.5792 - val_loss: 1.2897 - val_accuracy: 0.5395\n",
            "Epoch 40/50\n",
            "73/73 [==============================] - 31s 426ms/step - loss: 1.2314 - accuracy: 0.5788 - val_loss: 1.2807 - val_accuracy: 0.5395\n",
            "Epoch 41/50\n",
            "73/73 [==============================] - 31s 422ms/step - loss: 1.2267 - accuracy: 0.5792 - val_loss: 1.2618 - val_accuracy: 0.5461\n",
            "Epoch 42/50\n",
            "73/73 [==============================] - 31s 422ms/step - loss: 1.2231 - accuracy: 0.5766 - val_loss: 1.2545 - val_accuracy: 0.5461\n",
            "Epoch 43/50\n",
            "73/73 [==============================] - 31s 423ms/step - loss: 1.2169 - accuracy: 0.5771 - val_loss: 1.2585 - val_accuracy: 0.5411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F17NTUPkqyYe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78m69Vn7qyYh"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/Shareddrives/CTRC/jiwoo_model/ResNet50/my_Resnet_model.h5')\n",
        "plot_model(model,show_shapes=True,to_file='my_Resnet_model.png') "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpqHfyOzqyYi"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GYHBjxtqyYj"
      },
      "source": [
        "model= load_model('/content/drive/Shareddrives/CTRC/jiwoo_model/Resnet50/my_Resnet_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NWvZB1SqyYj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#predict=model.predict(#validationData의 feature)\n",
        "predict=model.predict(testGen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxRc-iMUcux1"
      },
      "source": [
        "## Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNK3bUu6e-ra"
      },
      "source": [
        "### 정확도 및 손실 그래프"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJIZvhqHcvrz"
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# acc = history.history['accuracy']\n",
        "# val_acc = history.history['val_accuracy']\n",
        "# loss = history.history['loss']\n",
        "# val_loss = history.history['val_loss']\n",
        "\n",
        "# epochs = range(len(acc))\n",
        "\n",
        "# plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "# plt.title('Training and validation accuracy')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.figure()\n",
        "\n",
        "# plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "# plt.title('Training and validation loss')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdNoQuQVfezK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-UXERAQdgoO"
      },
      "source": [
        "# 알고리즘 CNN\n",
        "* 심층 신경망(DNN, Deep Neural Network)\n",
        "* 합성곱 신경망(CNN, Convoultional Neural Network)\n",
        "* 순환 신경망(RNN, Recurrent Neural Network)\n",
        "* 제한 볼츠만 머신(RBM, Restricted Boltzmann Machine)\n",
        "* 심층 신뢰 신경망(DBN, Deep Belief Network)\n",
        "\n",
        "\n",
        "\n",
        "CNN. 합성곱신경망 [Convolutional Neural Network]\n",
        "\n",
        "CNN은 하나 이상의 합성곱 계층과 그 위에 올려진 일반적인 인공 신경망 계층들로 이루어져 있고, 가중치와 레이어들을 추가로 활용한다. 이러한 구조로 CNN은 2차원 구조의 입력 데이터를 충분히 활용할 수 있다. 다른 딥러닝 구조들과 비교했을 때, CNN은 영상과 음성 분야 모두에서 좋은 성능을 보인다. 또한 표준 역전달을 통해 훈련될 수 있고, 적은 수의 매개변수를 사용한다는 이점이 있다. \n",
        "\n",
        " CNN은 마지막 레이어에 손실 함수를 가지며, 우리가 일반 신경망을 학습시킬 때 사용하던 각종 기법들을 동일하게 적용할 수 있다. CNN은 이미지 및 비디오 인식, 추천 시스템 및 자연 언어 처리 등에 응용된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrLBvqEDMFIW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgWVnWK6zSLI"
      },
      "source": [
        "# 텐서플로우의 시각화 프레임워크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq9Poa3xzQ_6"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npCmrBeJLB2G"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=my_log_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqa33Z_PJh3_"
      },
      "source": [
        "# 최대 epoch\n",
        "```\n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
        "```\n",
        "성능이 증가하지 않는다고, 그 순간 바로 멈추는 것은 효과적이지않을 수 있다. patience 는 성능이 증가하지 않는 epoch 을 몇 번이나 허용할 것인가를 정의\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQzEGXRoLcm6"
      },
      "source": [
        "# ROC & 정밀도 및 재현율"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9t07olkLdtf"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "cm = confusion_matrix(validationGen, predict)\n",
        "print(cm)\n",
        "print( \"accuracy : \", accuracy_score( validationGen, predict ) ) # (cm[0][0]+cm[1][1])/(cm[0][0]+cm[1][1]+cm[1][0]+cm[0][1])\n",
        "print( \"recall(detection rate) : \", recall_score( y_test, predict ) )\n",
        "print( \"fallout (false alarm rate) : \",cm[1][0]/(cm[1][0]+cm[1][1]) )\n",
        "print( \"f1_score : \", f1_score(validationGen, predict) )\n",
        "print( \"roc_auc : \", roc_auc_score(validationGen, predict) )\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(validationGen, predict)\n",
        "\n",
        "plt.plot(fpr, tpr, 'o-', label=\"ROC Curve\")\n",
        "plt.plot([0,1],[0,1], 'k--')\n",
        "fallout = cm[1][0]/(cm[1][0]+cm[1][1])\n",
        "plt.plot([fallout], [recall_score( validationGen, predict )], 'ro', ms=10)\n",
        "plt.xlabel(\"fallout\")\n",
        "plt.ylabel(\"recall\")\n",
        "plt.title(\"ROC curve\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}