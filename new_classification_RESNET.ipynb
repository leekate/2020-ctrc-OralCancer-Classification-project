{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_classification_RESNET.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leekate/2020ctrc/blob/master/new_classification_RESNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zuwHf6FUgXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98bde3e4-c4b4-4e1e-dadd-614f3f929693"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V8MH55jEaNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e9fa78f-fa43-4daa-d9c9-140fae1a63bc"
      },
      "source": [
        "pip install dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dataset\n",
            "  Downloading https://files.pythonhosted.org/packages/98/37/7d5a3d47b663173af4066ef761462de2fbd22a893e0aa659ab07540e90b2/dataset-1.4.1-py2.py3-none-any.whl\n",
            "Collecting alembic>=0.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/aa/c261dfd7f4ba6ce4701846a2689a46e2a172e012171de4378fc2926e3bf0/alembic-1.4.3-py2.py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.2 in /usr/local/lib/python3.6/dist-packages (from dataset) (1.3.20)\n",
            "Collecting banal>=1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/3a/a0/6e64c775272209016bbd06de0c1f02388780a91e174aa79c4cdbab4968b5/banal-1.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic>=0.6.2->dataset) (2.8.1)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.0MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->alembic>=0.6.2->dataset) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic>=0.6.2->dataset) (1.1.1)\n",
            "Installing collected packages: Mako, python-editor, alembic, banal, dataset\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.3 banal-1.0.1 dataset-1.4.1 python-editor-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7jOTcBCaH-f"
      },
      "source": [
        "# Data Load, Read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAasPFcSXO0E"
      },
      "source": [
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def load_train(train_path, image_size, classes):\n",
        "    images = []\n",
        "    labels = []\n",
        "    ids = []\n",
        "    cls = []\n",
        "\n",
        "    print('Reading training images')\n",
        "    for fld in classes:\n",
        "        index = classes.index(fld)\n",
        "        print('Loading {} files (Index: {})'.format(fld, index))\n",
        "        path = os.path.join(train_path, fld, '*g')\n",
        "        files = glob.glob(path)\n",
        "        for fl in files:\n",
        "            image = cv2.imread(fl)\n",
        "            image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR)\n",
        "            images.append(image)\n",
        "            label = np.zeros(len(classes))\n",
        "            label[index] = 1.0\n",
        "            labels.append(label)\n",
        "            flbase = os.path.basename(fl)\n",
        "            ids.append(flbase)\n",
        "            cls.append(fld)\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    ids = np.array(ids)\n",
        "    cls = np.array(cls)\n",
        "  \n",
        "\n",
        "    return images, labels, ids, cls\n",
        "\n",
        "\n",
        "def load_test(test_path, image_size):\n",
        "    path = os.path.join(test_path, '*g')\n",
        "    files = sorted(glob.glob(path))\n",
        "\n",
        "    X_test = []\n",
        "    X_test_id = []\n",
        "    print(\"Reading test images\")\n",
        "    for fl in files:\n",
        "        \n",
        "        img = cv2.imread(fl)\n",
        "        img = cv2.resize(img, (image_size, image_size), cv2.INTER_LINEAR)\n",
        "        X_test.append(img)\n",
        "        X_test_id.append(flbase)\n",
        "        flbase = os.path.basename(fl)\n",
        "\n",
        "    X_test = np.array(X_test, dtype=np.uint8)\n",
        "    X_test = X_test.astype('float32')\n",
        "    X_test = X_test / 255\n",
        "    X_test_id = np.array(X_test_id)\n",
        "\n",
        "    return X_test, X_test_id\n",
        "\n",
        "\n",
        "class DataSet(object):\n",
        "\n",
        "    def __init__(self, images, labels, ids, cls):\n",
        "        \"\"\"Construct a DataSet. one_hot arg is used only if fake_data is true.\"\"\"\n",
        "\n",
        "        self._num_examples = images.shape[0]\n",
        "\n",
        "        # Convert shape from [num examples, rows, columns, depth]\n",
        "        # to [num examples, rows*columns] (assuming depth == 1)\n",
        "        # Convert from [0, 255] -> [0.0, 1.0].\n",
        "\n",
        "        images = images.astype(np.float32)\n",
        "        images = np.multiply(images, 1.0 / 255.0)\n",
        "\n",
        "        self._images = images\n",
        "        self._labels = labels\n",
        "        self._ids = ids\n",
        "        self._cls = cls\n",
        "        self._epochs_completed = 0\n",
        "        self._index_in_epoch = 0\n",
        "\n",
        "    @property\n",
        "    def images(self):\n",
        "        return self._images\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "        return self._labels\n",
        "\n",
        "    @property\n",
        "    def ids(self):\n",
        "        return self._ids\n",
        "\n",
        "    @property\n",
        "    def cls(self):\n",
        "        return self._cls\n",
        "\n",
        "    @property\n",
        "    def num_examples(self):\n",
        "        return self._num_examples\n",
        "\n",
        "    @property\n",
        "    def epochs_completed(self):\n",
        "        return self._epochs_completed\n",
        "\n",
        "    def next_batch(self, batch_size):\n",
        "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
        "        start = self._index_in_epoch\n",
        "        self._index_in_epoch += batch_size\n",
        "\n",
        "        if self._index_in_epoch > self._num_examples:\n",
        "            # Finished epoch\n",
        "            self._epochs_completed += 1\n",
        "\n",
        "            # # Shuffle the data (maybe)\n",
        "            # perm = np.arange(self._num_examples)\n",
        "            # np.random.shuffle(perm)\n",
        "            # self._images = self._images[perm]\n",
        "            # self._labels = self._labels[perm]\n",
        "            # Start next epoch\n",
        "\n",
        "            start = 0\n",
        "            self._index_in_epoch = batch_size\n",
        "            assert batch_size <= self._num_examples\n",
        "        end = self._index_in_epoch\n",
        "\n",
        "        return self._images[start:end], self._labels[start:end], self._ids[start:end], self._cls[start:end]\n",
        "\n",
        "\n",
        "def read_train_sets(train_path, image_size, classes, validation_size=0):\n",
        "    class DataSets(object):\n",
        "        pass\n",
        "\n",
        "    data_sets = DataSets()\n",
        "\n",
        "    images, labels, ids, cls = load_train(train_path, image_size, classes)\n",
        "    images, labels, ids, cls = shuffle(images, labels, ids, cls)  # shuffle the data\n",
        "\n",
        "    if isinstance(validation_size, float):\n",
        "        validation_size = int(validation_size * images.shape[0])\n",
        "\n",
        "    train_images = images\n",
        "    train_labels = labels\n",
        "    train_ids = ids\n",
        "    train_cls = cls\n",
        "\n",
        "    data_sets.train = DataSet(train_images, train_labels, train_ids, train_cls)\n",
        "\n",
        "    return data_sets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR6T7ZmRXP9j"
      },
      "source": [
        "def load_validation(validation_path, image_size, classes):\n",
        "    images2 = []\n",
        "    labels2 = []\n",
        "    ids2 = []\n",
        "    cls2 = []\n",
        "\n",
        "    print('Reading validation images')\n",
        "    for fld in classes:\n",
        "        index = classes.index(fld)\n",
        "        print('Loading {} files (Index: {})'.format(fld, index))\n",
        "        path = os.path.join(validation_path, fld, '*g')\n",
        "        files = glob.glob(path)\n",
        "        for fl in files:\n",
        "            image = cv2.imread(fl)\n",
        "            image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR)\n",
        "            images2.append(image)\n",
        "            label = np.zeros(len(classes))\n",
        "            label[index] = 1.0\n",
        "            labels2.append(label)\n",
        "            flbase = os.path.basename(fl)\n",
        "            ids2.append(flbase)\n",
        "            cls2.append(fld)\n",
        "    images2 = np.array(images2)\n",
        "    labels2 = np.array(labels2)\n",
        "    ids2 = np.array(ids2)\n",
        "    cls2 = np.array(cls2)\n",
        "  \n",
        "\n",
        "    return images2, labels2, ids2, cls2\n",
        "\n",
        "\n",
        "def read_validation_sets(validation_path, image_size, classes, validation_size=0):\n",
        "    class DataSets(object):\n",
        "        pass\n",
        "\n",
        "    data_sets = DataSets()\n",
        "\n",
        "    images2, labels2, ids2, cls2 = load_validation(validation_path, image_size, classes)\n",
        "    images2, labels2, ids2, cls2 = shuffle(images2, labels2, ids2, cls2)  # shuffle the data\n",
        "\n",
        "    if isinstance(validation_size, float):\n",
        "        validation_size = int(validation_size * images2.shape[0])\n",
        "\n",
        "    validation_images = images2\n",
        "    validation_labels = labels2\n",
        "    validation_ids = ids2\n",
        "    validation_cls = cls2\n",
        "\n",
        "    data_sets.valid = DataSet(validation_images, validation_labels, validation_ids, validation_cls)\n",
        "\n",
        "    return data_sets"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwkxE2C4XSup"
      },
      "source": [
        "def load_test(test_path, image_size, classes):\n",
        "    images3 = []\n",
        "    labels3 = []\n",
        "    ids3 = []\n",
        "    cls3 = []\n",
        "\n",
        "    print('Reading validation images')\n",
        "    for fld in classes:\n",
        "        index = classes.index(fld)\n",
        "        print('Loading {} files (Index: {})'.format(fld, index))\n",
        "        path = os.path.join(test_path, fld, '*g')\n",
        "        files = glob.glob(path)\n",
        "        for fl in files:\n",
        "            image = cv2.imread(fl)\n",
        "            image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR)\n",
        "            images3.append(image)\n",
        "            label = np.zeros(len(classes))\n",
        "            label[index] = 1.0\n",
        "            labels3.append(label)\n",
        "            flbase = os.path.basename(fl)\n",
        "            ids3.append(flbase)\n",
        "            cls3.append(fld)\n",
        "    images3 = np.array(images3)\n",
        "    labels3 = np.array(labels3)\n",
        "    ids3 = np.array(ids3)\n",
        "    cls3 = np.array(cls3)\n",
        "  \n",
        "\n",
        "    return images3, labels3, ids3, cls3\n",
        "\n",
        "\n",
        "def read_test_sets(test_path, image_size, classes, validation_size=0):\n",
        "    class DataSets(object):\n",
        "        pass\n",
        "\n",
        "    data_sets = DataSets()\n",
        "\n",
        "    images3, labels3, ids3, cls3 = load_test(test_path, image_size, classes)\n",
        "    images3, labels3, ids3, cls3 = shuffle(images3, labels3, ids3, cls3)  # shuffle the data\n",
        "\n",
        "    if isinstance(validation_size, float):\n",
        "        validation_size = int(validation_size * images3.shape[0])\n",
        "\n",
        "    test_images = images3\n",
        "    test_labels = labels3\n",
        "    test_ids = ids3\n",
        "    test_cls = cls3\n",
        "\n",
        "    data_sets.test = DataSet(test_images, test_labels, test_ids, test_cls)\n",
        "\n",
        "    return data_sets"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFEYiZ8baCnV"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea1AV3d6XVIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850a2161-02f9-4d2c-e482-ba2f69a30f8d"
      },
      "source": [
        "import time\n",
        "import math\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.compat.v1 as tf\n",
        "import cv2\n",
        "import dataset\n",
        "import os\n",
        "import keras\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from datetime import timedelta\n",
        "import seaborn as sn\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "#######################################################################\n",
        "\n",
        "filter_size1 = 7\n",
        "num_filters1 = 64\n",
        "\n",
        "filter_size2 = 1\n",
        "num_filters2 = 64\n",
        "\n",
        "filter_size3 = 3\n",
        "num_filters3 = 64\n",
        "\n",
        "filter_size4 = 1\n",
        "num_filters4 = 256\n",
        "\n",
        "filter_size5 = 1\n",
        "num_filters5 = 128\n",
        "\n",
        "filter_size6 = 3\n",
        "num_filters6 = 128\n",
        "\n",
        "filter_size7 = 1\n",
        "num_filters7 = 512\n",
        "\n",
        "filter_size8 = 1\n",
        "num_filters8 = 256\n",
        "\n",
        "filter_size9 = 3\n",
        "num_filters9 = 256\n",
        "\n",
        "filter_size10 = 1\n",
        "num_filters10 = 1024\n",
        "\n",
        "filter_size11 = 1\n",
        "num_filters11 = 512\n",
        "\n",
        "filter_size12 = 3\n",
        "num_filters12 = 512\n",
        "\n",
        "filter_size13 = 1\n",
        "num_filters13 = 2048\n",
        "\n",
        "#######################################################################\n",
        "\n",
        "# Fully-connected layer.\n",
        "# Number of neurons in fully-connected layer.\n",
        "# convolution layer 전체에 있는 뉴런 수 = 필터 역할\n",
        "# fc_size = 256             \n",
        "fc_size = 1000\n",
        "\n",
        "\n",
        "# Number of color channels for the images: 1 channel for gray-scale.\n",
        "num_channels = 3\n",
        "\n",
        "# image dimensions (only squares for now)\n",
        "img_size = 224\n",
        "\n",
        "\n",
        "#이전 층으로부터 받은 데이터에 대해 \n",
        "#뉴런의 수만큼 해당되는 영역만큼 합성곱을 진행, 반복\n",
        "\n",
        "\n",
        "# Size of image when flattened to a single dimension\n",
        "img_size_flat = img_size * img_size * num_channels\n",
        "\n",
        "# Tuple with height and width of images used to reshape arrays.\n",
        "img_shape = (img_size, img_size)\n",
        "\n",
        "# class info\n",
        "classes = ['1.Cancer', '2.Precancer', '3.Inflammatory', '4.Normal']\n",
        "num_classes = len(classes)\n",
        "\n",
        "# batch size\n",
        "batch_size = 32\n",
        "\n",
        "# # validation split\n",
        "# validation_size = .2\n",
        "\n",
        "# how long to wait after validation loss stops improving before terminating training\n",
        "early_stopping = None  # use None if you don't want to implement early stoping"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UHRTj6eXcuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680a4808-f5fb-42ef-c17d-4c7faaa5c73e"
      },
      "source": [
        "\n",
        "#######################################################################\n",
        "# 공유드라이브 주소로 수정\n",
        "train_path = '/content/drive/Shareddrives/CTRC/train2'\n",
        "validation_path = '/content/drive/Shareddrives/CTRC/validation2'\n",
        "test_path = '/content/drive/Shareddrives/CTRC/test2'\n",
        "checkpoint_dir = '/content/drive/My Drive/CTRC/RESNET/model'\n",
        "\n",
        "\n",
        "#######################################################################\n",
        "\n",
        "# data = read_train_sets(train_path, img_size, classes, validation_size=validation_size)\n",
        "# data2 = read_validation_sets(validation_path, img_size, classes, validation_size=validation_size)\n",
        "# data3 = read_test_sets(test_path, img_size, classes, validation_size=validation_size)\n",
        "\n",
        "data = read_train_sets(train_path, img_size, classes, validation_size=0)\n",
        "data2 = read_validation_sets(validation_path, img_size, classes, validation_size=0)\n",
        "data3 = read_test_sets(test_path, img_size, classes, validation_size=0)\n",
        "\n",
        "\n",
        "print(\"Size of:\")\n",
        "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
        "print(\"- Validation-set:\\t{}\".format(len(data2.valid.labels)))\n",
        "print(\"- Test-set:\\t\\t{}\".format(len(data3.test.labels)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading training images\n",
            "Loading 1.Cancer files (Index: 0)\n",
            "Loading 2.Precancer files (Index: 1)\n",
            "Loading 3.Inflammatory files (Index: 2)\n",
            "Loading 4.Normal files (Index: 3)\n",
            "Reading validation images\n",
            "Loading 1.Cancer files (Index: 0)\n",
            "Loading 2.Precancer files (Index: 1)\n",
            "Loading 3.Inflammatory files (Index: 2)\n",
            "Loading 4.Normal files (Index: 3)\n",
            "Reading validation images\n",
            "Loading 1.Cancer files (Index: 0)\n",
            "Loading 2.Precancer files (Index: 1)\n",
            "Loading 3.Inflammatory files (Index: 2)\n",
            "Loading 4.Normal files (Index: 3)\n",
            "Size of:\n",
            "- Training-set:\t\t4038\n",
            "- Validation-set:\t392\n",
            "- Test-set:\t\t392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpaEjHGTgR1p"
      },
      "source": [
        "def new_weights(shape):\r\n",
        "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\r\n",
        "    #tf.truncated_normal: 너무 작거나 너무 큰 값이 아닌 값으로 랜덤한 값을 가져오는 것\r\n",
        "\r\n",
        "def new_biases(length):\r\n",
        "    return tf.Variable(tf.constant(0.05, shape=[length]))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1Mb098qj28C"
      },
      "source": [
        "def new_conv_layer(input,              \n",
        "                   num_input_channels, \n",
        "                   filter_size,       \n",
        "                   num_filters,       \n",
        "                   use_pooling=True): \n",
        "\n",
        "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
        "\n",
        "    weights = new_weights(shape=shape)\n",
        "\n",
        "    biases = new_biases(length=num_filters)\n",
        "\n",
        "    layer = tf.nn.conv2d(input=input,\n",
        "                         filter=weights,\n",
        "                         strides=[1, 1, 1, 1],\n",
        "                         padding='SAME')\n",
        "\n",
        "    layer += biases\n",
        "\n",
        "    layer = tf.nn.conv2d(input=input,\n",
        "                         filter=weights,\n",
        "                         strides=[1, 1, 1, 1],\n",
        "                         padding='SAME')\n",
        "\n",
        "    layer += biases\n",
        "\n",
        "    if use_pooling:\n",
        "\n",
        "        layer = tf.nn.max_pool(value=layer,\n",
        "                               ksize=[1, 2, 2, 1],\n",
        "                               strides=[1, 2, 2, 1],\n",
        "                               padding='SAME')\n",
        "\n",
        "    layer = tf.nn.relu(layer)\n",
        "\n",
        "\n",
        "    return layer, weights\n",
        "\n",
        "def new_conv_layer_drop(input,              \n",
        "                   num_input_channels, \n",
        "                   filter_size,       \n",
        "                   num_filters,       \n",
        "                   use_pooling=True): \n",
        "\n",
        "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
        "\n",
        "    weights = new_weights(shape=shape)\n",
        "\n",
        "    biases = new_biases(length=num_filters)\n",
        "\n",
        "    layer = tf.nn.conv2d(input=input,\n",
        "                         filter=weights,\n",
        "                         strides=[1, 1, 1, 1],\n",
        "                         padding='SAME')\n",
        "\n",
        "    layer += biases\n",
        "\n",
        "    layer = tf.nn.conv2d(input=input,\n",
        "                         filter=weights,\n",
        "                         strides=[1, 1, 1, 1],\n",
        "                         padding='SAME')\n",
        "\n",
        "    layer += biases\n",
        "\n",
        "    if use_pooling:\n",
        "\n",
        "        layer = tf.nn.max_pool(value=layer,\n",
        "                               ksize=[1, 2, 2, 1],\n",
        "                               strides=[1, 2, 2, 1],\n",
        "                               padding='SAME')\n",
        "\n",
        "    layer = tf.nn.relu(layer)\n",
        "    layer = tf.nn.dropout(layer, keep_prob=keep_prob)\n",
        "    \n",
        "    return layer, weights\n",
        "\n",
        "\n",
        "def flatten_layer(layer):\n",
        "\n",
        "    layer_shape = layer.get_shape()\n",
        "\n",
        "    num_features = layer_shape[1:8].num_elements()\n",
        "    \n",
        "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
        "\n",
        "    return layer_flat, num_features\n",
        "\n",
        "  \n",
        "def new_fc_layer(input,        \n",
        "                 num_inputs,    \n",
        "                 num_outputs,  \n",
        "                 use_relu=True):\n",
        "\n",
        "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
        "    biases = new_biases(length=num_outputs)\n",
        "\n",
        "    layer = tf.matmul(input, weights) + biases\n",
        "    \n",
        "    if use_relu:\n",
        "        layer = tf.nn.relu(layer)\n",
        "\n",
        "    return layer\n",
        "\n",
        "\n",
        "\n",
        "x = tf.compat.v1.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
        "\n",
        "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
        "\n",
        "y_true = tf.compat.v1.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
        "\n",
        "y_true_cls = tf.argmax(y_true, axis=1)\n",
        "\n",
        "keep_prob = tf.compat.v1.placeholder(tf.float32)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDZiWgIMj3G_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd0a5aa1-8606-4ae3-b030-60044ab41c85"
      },
      "source": [
        "#######################################################################\\\n",
        "layer_conv1, weights_conv1 = \\\n",
        "    new_conv_layer_drop(input=x_image,\n",
        "                   num_input_channels=num_channels,\n",
        "                   filter_size=filter_size1,\n",
        "                   num_filters=num_filters1,\n",
        "                   use_pooling=True)\n",
        "     \n",
        "layer_conv2, weights_conv2 = \\\n",
        "    new_conv_layer(input=layer_conv1,\n",
        "                   num_input_channels=num_filters1,\n",
        "                   filter_size=filter_size2,\n",
        "                   num_filters=num_filters2,\n",
        "                   use_pooling=True)\n",
        "    \n",
        "layer_conv3, weights_conv3 = \\\n",
        "    new_conv_layer_drop(input=layer_conv2,\n",
        "                   num_input_channels=num_filters2,\n",
        "                   filter_size=filter_size3,\n",
        "                   num_filters=num_filters3,\n",
        "                   use_pooling=True)\n",
        "    \n",
        "layer_conv4, weights_conv4 = \\\n",
        "    new_conv_layer(input=layer_conv3,\n",
        "                   num_input_channels=num_filters3,\n",
        "                   filter_size=filter_size4,\n",
        "                   num_filters=num_filters4,\n",
        "                   use_pooling=True)\n",
        "    \n",
        "layer_conv5, weights_conv5 = \\\n",
        "    new_conv_layer_drop(input=layer_conv4,\n",
        "                   num_input_channels=num_filters4,\n",
        "                   filter_size=filter_size5,\n",
        "                   num_filters=num_filters5,\n",
        "                   use_pooling=True)\n",
        "    \n",
        "layer_conv6, weights_conv6 = \\\n",
        "    new_conv_layer(input=layer_conv5,\n",
        "                   num_input_channels=num_filters5,\n",
        "                   filter_size=filter_size6,\n",
        "                   num_filters=num_filters6,\n",
        "                   use_pooling=True)\n",
        "    \n",
        "layer_conv7, weights_conv7 = \\\n",
        "    new_conv_layer_drop(input=layer_conv6,\n",
        "                   num_input_channels=num_filters6,\n",
        "                   filter_size=filter_size7,\n",
        "                   num_filters=num_filters7,\n",
        "                   use_pooling=True)\n",
        "\n",
        "layer_conv8, weights_conv8 = \\\n",
        "    new_conv_layer_drop(input=layer_conv7,\n",
        "                   num_input_channels=num_filters7,\n",
        "                   filter_size=filter_size8,\n",
        "                   num_filters=num_filters8,\n",
        "                   use_pooling=True)\n",
        "     \n",
        "layer_conv9, weights_conv9 = \\\n",
        "    new_conv_layer(input=layer_conv8,\n",
        "                   num_input_channels=num_filters8,\n",
        "                   filter_size=filter_size9,\n",
        "                   num_filters=num_filters9,\n",
        "                   use_pooling=True)\n",
        "    \n",
        "layer_conv10, weights_conv10 = \\\n",
        "    new_conv_layer_drop(input=layer_conv9,\n",
        "                   num_input_channels=num_filters9,\n",
        "                   filter_size=filter_size10,\n",
        "                   num_filters=num_filters10,\n",
        "                   use_pooling=True)\n",
        "    \n",
        "layer_conv11, weights_conv11 = \\\n",
        "    new_conv_layer(input=layer_conv10,\n",
        "                   num_input_channels=num_filters10,\n",
        "                   filter_size=filter_size11,\n",
        "                   num_filters=num_filters11,\n",
        "                   use_pooling=True)\n",
        "    \n",
        "layer_conv12, weights_conv12 = \\\n",
        "    new_conv_layer_drop(input=layer_conv11,\n",
        "                   num_input_channels=num_filters11,\n",
        "                   filter_size=filter_size12,\n",
        "                   num_filters=num_filters12,\n",
        "                   use_pooling=True)\n",
        "    \n",
        "layer_conv13, weights_conv13 = \\\n",
        "    new_conv_layer(input=layer_conv12,\n",
        "                   num_input_channels=num_filters12,\n",
        "                   filter_size=filter_size13,\n",
        "                   num_filters=num_filters13,\n",
        "                   use_pooling=True)\n",
        "\n",
        "\n",
        "\n",
        "layer_flat, num_features = flatten_layer(layer_conv13)\n",
        "\n",
        "\n",
        "\n",
        "layer_fc1 = new_fc_layer(input=layer_flat,\n",
        "                         num_inputs=num_features,\n",
        "                         num_outputs=fc_size,\n",
        "                         use_relu=True)\n",
        "\n",
        "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
        "                         num_inputs=fc_size,\n",
        "                         num_outputs=128,\n",
        "                         use_relu=False)\n",
        "\n",
        "layer_fc3 = new_fc_layer(input=layer_fc2,\n",
        "                         num_inputs=128,\n",
        "                         num_outputs=64,\n",
        "                         use_relu=False)\n",
        "\n",
        "'''layer_fc4 = new_fc_layer(input=layer_fc3,\n",
        "                         num_inputs=64,\n",
        "                         num_outputs=32,\n",
        "                         use_relu=False)\n",
        "\n",
        "layer_fc5 = new_fc_layer(input=layer_fc4,\n",
        "                         num_inputs=32,\n",
        "                         num_outputs=16,\n",
        "                         use_relu=False)\n",
        "\n",
        "layer_fc6 = new_fc_layer(input=layer_fc5,\n",
        "                         num_inputs=16,\n",
        "                         num_outputs=num_classes,                        \n",
        "                         use_relu=False)'''\n",
        "\n",
        "#######################################################################\n",
        "\n",
        "\n",
        "y_pred = tf.nn.softmax(layer_fc3)\n",
        "\n",
        "y_pred_cls = tf.argmax(y_pred, axis=1)\n",
        "\n",
        "loss_func = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc3, labels=y_true)\n",
        "\n",
        "cost = tf.reduce_mean(loss_func)\n",
        "\n",
        "regularizer = tf.nn.l2_loss(weights_conv13)\n",
        "beta = 0.001\n",
        "cost = tf.reduce_mean(cost + beta*regularizer)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
        "\n",
        "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1bwlIuRj3Rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5290a46-9b7c-4402-8860-8a79b8e542fa"
      },
      "source": [
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
        "from yellowbrick.classifier import ROCAUC"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp7NT_sktKSO"
      },
      "source": [
        "각 epoch당 학습 결과 표시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC2FqbukrX5a"
      },
      "source": [
        "session = tf.Session()\n",
        "\n",
        "session.run(tf.global_variables_initializer())\n",
        "\n",
        "train_batch_size = batch_size\n",
        "\n",
        "save_dir=\"/content/drive/Shareddrives/CTRC/model\"\n",
        "\n",
        "def print_progress(epoch, feed_dict_train, val_loss):\n",
        "    acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
        "    msg = \"Epoch {0} --- Training Accuracy: {1:>6.1%},  Validation Loss: {2:.3f}\"\n",
        "    os.path.join(save_dir, \"epoch{epoch:03d}_valloss{val_loss:0.4f}.hdf5\")\n",
        "    print(msg.format(epoch + 1, acc, val_loss))\n",
        "\n",
        "    if epoch <= 47:\n",
        "      print(print_validation_accuracy(show_confusion_matrix=False))\n",
        "      print(print_test_accuracy(show_confusion_matrix=False))\n",
        "    else:\n",
        "      print(print_validation_accuracy(show_confusion_matrix=True))\n",
        "      print(print_test_accuracy(show_confusion_matrix=True))\n",
        "\n",
        "\n",
        "total_iterations = 0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmCAkkBQtah9"
      },
      "source": [
        "train data 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omo5o5ketaFe"
      },
      "source": [
        "def optimize(num_iterations):\n",
        "    global total_iterations\n",
        "    \n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience = 0\n",
        "\n",
        "    for i in range(total_iterations,\n",
        "                   total_iterations + num_iterations):\n",
        "\n",
        "        \n",
        "\n",
        "        x_batch, y_true_batch, _, cls_batch = data.train.next_batch(train_batch_size)\n",
        "        x_valid_batch, y_valid_batch, _, valid_cls_batch = data2.valid.next_batch(train_batch_size)\n",
        "        x_test_batch, y_test_batch, _, test_cls_batch = data3.test.next_batch(train_batch_size)\n",
        "\n",
        "        x_batch = x_batch.reshape(train_batch_size, img_size_flat)\n",
        "        x_valid_batch = x_valid_batch.reshape(train_batch_size, img_size_flat)\n",
        "        x_test_batch = x_test_batch.reshape(train_batch_size, img_size_flat)\n",
        "\n",
        "        feed_dict_train = {x: x_batch,\n",
        "                           y_true: y_true_batch, keep_prob: 0.70}\n",
        "        \n",
        "        feed_dict_validate = {x: x_valid_batch,\n",
        "                              y_true: y_valid_batch, keep_prob : 0.70}\n",
        "\n",
        "        feed_dict_test = {x: x_test_batch,\n",
        "                          y_true: y_test_batch, keep_prob : 0.70}\n",
        "\n",
        "        session.run(optimizer, feed_dict=feed_dict_train)\n",
        "        \n",
        "        if i % int(data.train.num_examples/batch_size) == 0: \n",
        "            val_loss = session.run(cost, feed_dict=feed_dict_validate)\n",
        "            epoch = int(i / int(data.train.num_examples/batch_size))\n",
        "\n",
        "            print_progress(epoch, feed_dict_train, val_loss)\n",
        "            \n",
        "            if early_stopping:    \n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    patience = 0\n",
        "                else:\n",
        "                    patience += 1\n",
        "\n",
        "                if patience == early_stopping:\n",
        "                    break\n",
        "\n",
        "\n",
        "    total_iterations += num_iterations\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    time_dif = end_time - start_time\n",
        "\n",
        "    print(\"Time elapsed: \" + str(timedelta(seconds=int(round(time_dif)))))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuxQbVVeuV-_"
      },
      "source": [
        "validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXOOM3ajuVH9"
      },
      "source": [
        "def print_validation_accuracy(show_example_errors=False, show_confusion_matrix=False):\n",
        "\n",
        "    num_test = len(data2.valid.images)\n",
        "\n",
        "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    while i < num_test:\n",
        " \n",
        "        j = min(i + batch_size, num_test)\n",
        "\n",
        "        images = data2.valid.images[i:j, :].reshape(-1, img_size_flat)\n",
        "        \n",
        "        labels = data2.valid.labels[i:j, :]\n",
        "\n",
        "        feed_dict = {x: images, y_true: labels, keep_prob: 0.70}\n",
        "\n",
        "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
        "\n",
        "        i = j\n",
        "\n",
        "\n",
        "    cls_true = np.array(data2.valid.cls)\n",
        "    cls_pred = np.array([classes[x] for x in cls_pred])\n",
        "\n",
        " \n",
        "\n",
        "    correct = (cls_true == cls_pred)\n",
        "\n",
        "    correct_sum = correct.sum()\n",
        "\n",
        "    acc = float(correct_sum) / num_test\n",
        "\n",
        "    msg = \"Validation Accuracy: {0:.1%} ({1} / {2})\"\n",
        "    print(msg.format(acc, correct_sum, num_test))\n",
        "\n",
        "    if show_example_errors:\n",
        "        print(\"Example errors:\")\n",
        "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
        "\n",
        "    if show_confusion_matrix:\n",
        "        print(\"Confusion Matrix:\")\n",
        "        plot_confusion_matrix(cls_pred=cls_pred)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NDCx8SDub_O"
      },
      "source": [
        "test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou-zRKfJujcy"
      },
      "source": [
        "def print_test_accuracy(show_example_errors=False, show_confusion_matrix=False):\n",
        "\n",
        "    num_test2 = len(data3.test.images)\n",
        "\n",
        "    cls_pred2 = np.zeros(shape=num_test2, dtype=np.int)\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    while i < num_test2:\n",
        " \n",
        "        j = min(i + batch_size, num_test2)\n",
        "\n",
        "        images = data3.test.images[i:j, :].reshape(-1, img_size_flat)\n",
        "        \n",
        "        labels = data3.test.labels[i:j, :]\n",
        "\n",
        "        feed_dict = {x: images, y_true: labels, keep_prob: 0.70}\n",
        "\n",
        "        cls_pred2[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
        "\n",
        "        i = j\n",
        "\n",
        "\n",
        "    cls_true2 = np.array(data3.test.cls)\n",
        "    cls_pred2 = np.array([classes[x] for x in cls_pred2])\n",
        "\n",
        " \n",
        "\n",
        "    correct = (cls_true2 == cls_pred2)\n",
        "\n",
        "    correct_sum = correct.sum()\n",
        "\n",
        "    acc = float(correct_sum) / num_test2\n",
        "\n",
        "    msg = \"Test Accuracy: {0:.1%} ({1} / {2})\"\n",
        "    print(msg.format(acc, correct_sum, num_test2))\n",
        "\n",
        "    if show_example_errors:\n",
        "        print(\"Example errors:\")\n",
        "        plot_example_errors(cls_pred2=cls_pred2, correct=correct)\n",
        "\n",
        "    if show_confusion_matrix:\n",
        "        print(\"Confusion Matrix:\")\n",
        "        plot_confusion_matrix2(cls_pred2=cls_pred2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDu8NXYjulqZ"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.metrics import roc_curve"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F6Zevqbunfc"
      },
      "source": [
        "혼동 행렬 1 (validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXobAw7mupuD"
      },
      "source": [
        "def plot_confusion_matrix(cls_pred):\n",
        "    \n",
        "    cls_true = data2.valid.cls\n",
        "\n",
        "    cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)\n",
        "    \n",
        "    print(cm)\n",
        "    \n",
        "    plt.matshow(cm, cmap=plt.cm.Wistia_r)\n",
        "\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(num_classes)\n",
        "    plt.xticks(tick_marks, range(num_classes))\n",
        "    plt.yticks(tick_marks, range(num_classes))\n",
        "\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    for i in range(0,4):\n",
        "      for j in range(0,4):\n",
        "        plt.text(j,i,str(cm[i][j]))\n",
        "    plt.show()\n",
        "\n",
        "    print(\"1.Cancer의 정밀도 : \", (cm[0,0]/(cm[0,0]+cm[1,0]+cm[2,0]+cm[3,0]))*100, \"%\")\n",
        "    print(\"1.Cancer의 재현율 : \", (cm[0,0]/(cm[0,0]+cm[0,1]+cm[0,2]+cm[0,3]))*100, \"%\")\n",
        "    print(\"2.Precancer의 정밀도 : \", (cm[1,1]/(cm[0,1]+cm[1,1]+cm[2,1]+cm[3,1]))*100, \"%\")\n",
        "    print(\"2.Precancer의 재현율 : \", (cm[1,1]/(cm[1,0]+cm[1,1]+cm[1,2]+cm[1,3]))*100, \"%\")\n",
        "    print(\"3.Inflammatory의 정밀도 : \", (cm[2,2]/(cm[0,2]+cm[1,2]+cm[2,2]+cm[3,2]))*100, \"%\")\n",
        "    print(\"3.Inflammatory의 재현율 : \", (cm[2,2]/(cm[2,0]+cm[2,1]+cm[2,2]+cm[2,3]))*100, \"%\")\n",
        "    print(\"4.Normal의 정밀도 : \", (cm[3,3]/(cm[0,3]+cm[1,3]+cm[2,3]+cm[3,3]))*100, \"%\")\n",
        "    print(\"4.Normal의 재현율 : \", (cm[3,3]/(cm[3,0]+cm[3,1]+cm[3,2]+cm[3,3]))*100, \"%\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grwAER5DuxLe"
      },
      "source": [
        "혼동 행렬 2 + ROC (test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjCjCHEAu0H8"
      },
      "source": [
        "def plot_confusion_matrix2(cls_pred2):\n",
        "    \n",
        "    cls_true2 = data3.test.cls\n",
        "\n",
        "    cm = confusion_matrix(y_true=cls_true2, y_pred=cls_pred2)\n",
        "    \n",
        "    print(cm)\n",
        "    \n",
        "    plt.matshow(cm, cmap=plt.cm.Wistia_r)\n",
        "\n",
        "    plt.colorbar()\n",
        "    \n",
        "    plt.title('Test Confusion Matrix')\n",
        "    tick_marks = np.arange(num_classes)\n",
        "    plt.xticks(tick_marks, range(num_classes))\n",
        "    plt.yticks(tick_marks, range(num_classes))\n",
        "    plt.grid(False)\n",
        "\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    for i in range(0,4):\n",
        "      for j in range(0,4):\n",
        "        plt.text(j,i,str(cm[i][j]))\n",
        "    plt.show()\n",
        "\n",
        "    print(\"1.Cancer의 정밀도 : \", (cm[0,0]/(cm[0,0]+cm[1,0]+cm[2,0]+cm[3,0]))*100, \"%\")\n",
        "    print(\"1.Cancer의 재현율 : \", (cm[0,0]/(cm[0,0]+cm[0,1]+cm[0,2]+cm[0,3]))*100, \"%\")\n",
        "    print(\"2.Precancer의 정밀도 : \", (cm[1,1]/(cm[0,1]+cm[1,1]+cm[2,1]+cm[3,1]))*100, \"%\")\n",
        "    print(\"2.Precancer의 재현율 : \", (cm[1,1]/(cm[1,0]+cm[1,1]+cm[1,2]+cm[1,3]))*100, \"%\")\n",
        "    print(\"3.Inflammatory의 정밀도 : \", (cm[2,2]/(cm[0,2]+cm[1,2]+cm[2,2]+cm[3,2]))*100, \"%\")\n",
        "    print(\"3.Inflammatory의 재현율 : \", (cm[2,2]/(cm[2,0]+cm[2,1]+cm[2,2]+cm[2,3]))*100, \"%\")\n",
        "    print(\"4.Normal의 정밀도 : \", (cm[3,3]/(cm[0,3]+cm[1,3]+cm[2,3]+cm[3,3]))*100, \"%\")\n",
        "    print(\"4.Normal의 재현율 : \", (cm[3,3]/(cm[3,0]+cm[3,1]+cm[3,2]+cm[3,3]))*100, \"%\")\n",
        "\n",
        "    \n",
        "    cls_true2 = cls_true2.tolist()\n",
        "    cls_pred2 = cls_pred2.tolist()\n",
        "\n",
        "    real_true1 = []\n",
        "    real_pred1 = []\n",
        "\n",
        "    real_true2 = []\n",
        "    real_pred2 = []\n",
        "\n",
        "    real_true3 = []\n",
        "    real_pred3 = []\n",
        "\n",
        "    real_true4 = []\n",
        "    real_pred4 = []\n",
        "\n",
        "    i=0\n",
        "    j=0\n",
        "    k=0\n",
        "    l=0\n",
        "\n",
        "    for i in range(len(cls_true2)):\n",
        "      if cls_true2[i] == \"1.Cancer\":\n",
        "        real_true1.append(1)\n",
        "        if cls_true2[i] == cls_pred2[i]:\n",
        "          real_pred1.append(1)\n",
        "        else:\n",
        "          real_pred1.append(0)\n",
        "\n",
        "\n",
        "    for j in range(len(cls_true2)):\n",
        "      if cls_true2[j] == \"1.Cancer\":\n",
        "        real_true2.append(1)\n",
        "        if cls_true2[j] == cls_pred2[j]:\n",
        "          real_pred2.append(1)\n",
        "        else:\n",
        "          real_pred2.append(0)\n",
        "\n",
        "\n",
        "    for k in range(len(cls_true2)):\n",
        "      if cls_true2[k] == \"1.Cancer\":\n",
        "        real_true3.append(1)\n",
        "        if cls_true2[k] == cls_pred2[k]:\n",
        "          real_pred3.append(1)\n",
        "        else:\n",
        "          real_pred3.append(0)\n",
        "   \n",
        "\n",
        "    for l in range(len(cls_true2)):\n",
        "      if cls_true2[l] == \"1.Cancer\":\n",
        "        real_true4.append(1)\n",
        "        if cls_true2[l] == cls_pred2[l]:\n",
        "          real_pred4.append(1)\n",
        "        else:\n",
        "          real_pred4.append(0)\n",
        "    \n",
        "\n",
        "    real_true1 = np.array(real_true1)\n",
        "    real_pred1 = np.array(real_pred1)\n",
        "\n",
        "    real_true2 = np.array(real_true2)\n",
        "    real_pred2 = np.array(real_pred2)\n",
        "\n",
        "    real_true3 = np.array(real_true3)\n",
        "    real_pred3 = np.array(real_pred3)\n",
        "\n",
        "    real_true4 = np.array(real_true4)\n",
        "    real_pred4 = np.array(real_pred4)\n",
        "\n",
        "\n",
        "    print( \"Cancer_roc_auc : \", roc_auc_score(real_true1, real_pred1, multi_class='ovr', average='micro'))\n",
        "    print( \"Precancer_roc_auc : \", roc_auc_score(real_true2, real_pred2, multi_class='ovr', average='micro'))\n",
        "    print( \"Inflammatory_roc_auc : \", roc_auc_score(real_true3, real_pred3, multi_class='ovr', average='micro'))\n",
        "    print( \"Normal_roc_auc : \", roc_auc_score(real_true4, real_pred4, multi_class='ovr', average='micro'))\n",
        "\n",
        "\n",
        "    can = roc_auc_score(real_true1, real_pred1, multi_class='ovr', average='micro')\n",
        "    pre = roc_auc_score(real_true2, real_pred2, multi_class='ovr', average='micro')\n",
        "    inf = roc_auc_score(real_true3, real_pred3, multi_class='ovr', average='micro')\n",
        "    nor = roc_auc_score(real_true4, real_pred4, multi_class='ovr', average='micro')\n",
        "\n",
        "\n",
        "\n",
        "    fpr1, tpr1, threshold1 = roc_curve(real_true1, real_pred1)\n",
        "    fpr2, tpr2, threshold2 = roc_curve(real_true2, real_pred2)\n",
        "    fpr3, tpr3, threshold3 = roc_curve(real_true3, real_pred3)\n",
        "    fpr4, tpr4, threshold4 = roc_curve(real_true4, real_pred4)\n",
        "\n",
        "\n",
        "    plt.plot(fpr1, tpr1, '-', label=\"Cancer ROC Curve = %f\"%(can), color='r')\n",
        "    plt.plot(fpr2, tpr2, '-', label=\"Precancer ROC Curve = %f\"%(pre), color='m')\n",
        "    plt.plot(fpr3, tpr3, '-', label=\"Inflammatory ROC Curve = %f\"%(inf), color='g')\n",
        "    plt.plot(fpr4, tpr4, '-', label=\"Normal ROC Curve = %f\"%(nor), color='b')\n",
        "    plt.plot([0,1],[0,1], 'k--')\n",
        "    plt.axis([0,1,0,1])\n",
        "\n",
        "    plt.xlabel(\"fpr\")\n",
        "    plt.ylabel(\"tpr\")\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EBnOecZu-Fl"
      },
      "source": [
        "실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQedM6MWj3lD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6d4b859-abf6-4abd-e896-13821eeaa8a2"
      },
      "source": [
        "optimize(num_iterations=1000000)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[32,64] labels_size=[32,4]\n\t [[{{node softmax_cross_entropy_with_logits}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3af8205977c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-aa3d6e40c1d5>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(num_iterations)\u001b[0m\n\u001b[1;32m     30\u001b[0m                           y_true: y_test_batch, keep_prob : 0.70}\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[32,64] labels_size=[32,4]\n\t [[node softmax_cross_entropy_with_logits (defined at <ipython-input-10-30b88a26f9b6>:123) ]]\n\nOriginal stack trace for 'softmax_cross_entropy_with_logits':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 548, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 462, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 492, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 444, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-30b88a26f9b6>\", line 123, in <module>\n    loss_func = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc3, labels=y_true)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\", line 3902, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 10889, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3485, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1949, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC8MqRlchEGH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}